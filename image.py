import streamlit as st
from PIL import Image
from io import BytesIO
import os

# For Text (Translation)
import google.generativeai as genga
# For Images (Client style)
from google import genai as genai_client
from google.genai import types as genai_client_types

from langdetect import detect, LangDetectException

# --- Streamlit App ---

st.set_page_config(page_title="æ–‡å­—ç”Ÿæˆå›¾ç‰‡", layout="wide")

st.title("ğŸ¨ æ–‡å­—ç”Ÿæˆå›¾ç‰‡ Web æœåŠ¡")
st.caption("ä½¿ç”¨ Google Imagen 3 æ¨¡å‹")

# API Key è¾“å…¥
st.sidebar.header("é…ç½®")
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.info("è¯·è¾“å…¥æ‚¨çš„ Google AI API Key ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
    st.sidebar.warning("API Key æœªæä¾›ã€‚")

# ç”¨æˆ·è¾“å…¥
st.sidebar.header("å›¾ç‰‡å‚æ•°")
prompt = st.sidebar.text_area("å›¾ç‰‡æè¿° (Prompt):", "ä¸€ä¸ªå®‡èˆªå‘˜åœ¨æœˆçƒä¸Šéª‘ç€å½©è™¹è‰²çš„ç‹¬è§’å…½ï¼ŒèƒŒæ™¯æ˜¯æ˜Ÿç©ºã€‚", height=150)
# num_images = st.sidebar.slider("ç”Ÿæˆå›¾ç‰‡æ•°é‡:", 1, 4, 4, help="ç›®å‰ä»£ç å›ºå®šä¸º4å¼ ï¼Œæ­¤æ»‘å—ä»…ä¸ºç¤ºä¾‹ã€‚")
# æ ¹æ®ç”¨æˆ·æä¾›çš„ä»£ç ï¼Œå›ºå®šç”Ÿæˆ4å¼ å›¾ç‰‡
fixed_num_images = 4

# ç”ŸæˆæŒ‰é’®
generate_button = st.sidebar.button("âœ¨ ç”Ÿæˆå›¾ç‰‡", use_container_width=True, disabled=not api_key)

st.markdown("---")

if generate_button:
    if not api_key:
        st.error("âŒ è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ Google AI API Keyã€‚")
    elif not prompt:
        st.error("âŒ è¯·è¾“å…¥å›¾ç‰‡æè¿° (prompt)ã€‚")
    else:
        translated_prompt = prompt
        original_language = "en"

        try:
            # Detect language
            original_language = detect(prompt)
            st.info(f"æ£€æµ‹åˆ°è¾“å…¥è¯­è¨€: {original_language}")

            if original_language != "en":
                st.info(f"è¾“å…¥è¯­è¨€éè‹±æ–‡ ({original_language})ï¼Œæ­£åœ¨å°è¯•ç¿»è¯‘...")
                # Using gemini-1.5-flash for translation
                # Initialize the model directly
                # Ensure API key is configured for the text generation module
                genga.configure(api_key=api_key) # Configure API key globally using genga
                translation_model = genga.GenerativeModel("gemini-2.0-flash") # Use genga

                # Simple translation prompt
                translation_response = translation_model.generate_content(f"Translate the following text to English: {prompt}")

                if translation_response and translation_response.text:
                    translated_prompt = translation_response.text.strip()
                    st.success(f"ç¿»è¯‘æˆåŠŸï¼ç¿»è¯‘åçš„ Prompt: {translated_prompt}")
                else:
                    st.warning("âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
                    translated_prompt = prompt # Fallback to original prompt
            else:
                st.info("è¾“å…¥è¯­è¨€ä¸ºè‹±æ–‡ï¼Œæ— éœ€ç¿»è¯‘ã€‚")

        except LangDetectException:
            st.warning("âš ï¸ è¯­è¨€æ£€æµ‹å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
            translated_prompt = prompt # Fallback to original prompt
        except Exception as translation_err:
            st.error(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {translation_err}")
            st.warning("âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
            translated_prompt = prompt # Fallback to original prompt


        try:
            # Using user provided code structure for image generation
            # API key is already configured globally

            with st.spinner(f"ğŸ§  æ­£åœ¨ç”Ÿæˆ {fixed_num_images} å¼ å›¾ç‰‡ä¸­ï¼Œè¯·ç¨å€™..."):
                # Instantiate the genai_client Client for images
                client = genai_client.Client(api_key=api_key)

                # Call client.generate_images (trying direct method on client)
                response = client.models.generate_image( # Changed from client.models.generate_images
                    model='imagen-3.0-generate-002', # This model name might need to be 'models/imagen-3.0-generate-002'
                    prompt=translated_prompt,
                    config=genai_client_types.GenerateImageConfig( # Use genai_client_types
                        number_of_images=fixed_num_images,
                    )
                )

            # Process the response assuming it has a 'generated_images' attribute
            # This structure is based on the user's snippet for client.models.generate_images
            # If client.generate_images has a different response structure, this may need adjustment
            if response and hasattr(response, 'generated_images') and response.generated_images:
                st.success(f"ğŸ‰ æˆåŠŸç”Ÿæˆ {len(response.generated_images)} å¼ å›¾ç‰‡ï¼")

                # Display images
                cols = st.columns(2)
                for i, generated_image in enumerate(response.generated_images):
                    try:
                        # Access image bytes as per the user's provided snippet and original code
                        image_bytes = generated_image.image.image_bytes
                        image = Image.open(BytesIO(image_bytes))
                        with cols[i % 2]:
                            st.image(image, caption=f"å›¾ç‰‡ {i+1} - {prompt[:30]}...", use_column_width=True)
                    except Exception as img_err:
                        st.error(f"å¤„ç†å›¾ç‰‡ {i+1} æ—¶å‡ºé”™: {img_err}")
            else:
                st.warning("âš ï¸ æœªèƒ½ç”Ÿæˆå›¾ç‰‡ã€‚å¯èƒ½æ˜¯æç¤ºè¯ä¸å½“ã€æ¨¡å‹é…ç½®é—®é¢˜ã€API æƒé™ä¸è¶³ï¼Œæˆ–å“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸã€‚")

        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
            

# ä½¿ç”¨è¯´æ˜å’Œè„šæ³¨
st.sidebar.markdown("---")
st.sidebar.markdown("""
**ä½¿ç”¨è¯´æ˜:**
1. è¯¥æ¨¡å‹åªæ”¯æŒè‹±æ–‡çš„æç¤ºè¯ã€‚è¯·ä½¿ç”¨è‹±æ–‡å†™æç¤ºè¯ï¼Œè‹¥ä½¿ç”¨å…¶ä»–è¯­éŸ³ï¼Œä¼šè‡ªåŠ¨ç¿»è¯‘æˆè‹±æ–‡ååœ¨ç”Ÿæˆå›¾ç‰‡
""")

st.markdown("---")
st.markdown("<p style='text-align: center;'>ç”± AI åŠ©æ‰‹åŸºäºæ‚¨çš„ä»£ç æ„å»º</p>", unsafe_allow_html=True)
