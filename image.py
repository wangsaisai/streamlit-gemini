import streamlit as st
from PIL import Image
from io import BytesIO
import os
import logging
from datetime import datetime

# For Text (Translation)
import google.generativeai as genga
# For Images (Client style)
from google import genai as genai_client
from google.genai import types as genai_client_types

from langdetect import detect, LangDetectException


# --- Helper Functions ---
def translate_text_to_english(text: str, api_key: str) -> tuple[str, str | None]:
    """
    Detects the language of the input text and translates it to English if it's not already English.
    Returns the translated text (or original if already English/translation failed) and the detected language.
    """
    original_language = "en"
    translated_text = text

    try:
        original_language = detect(text)
        st.info(f"æ£€æµ‹åˆ°è¾“å…¥è¯­è¨€: {original_language}")

        if original_language != "en":
            st.info(f"è¾“å…¥è¯­è¨€éè‹±æ–‡ ({original_language})ï¼Œæ­£åœ¨å°è¯•ç¿»è¯‘...")
            genga.configure(api_key=api_key)
            # Using a specific model known for good translation, adjust if needed
            translation_model = genga.GenerativeModel("gemini-2.0-flash")
            
            # Optimized prompt for direct translation
            prompt_template = f"Translate the following text from {original_language} to English. Provide only the translated text, without any additional explanations or alternative translations:\n\n{text}"
            
            translation_response = translation_model.generate_content(prompt_template)

            if translation_response and translation_response.text:
                translated_text = translation_response.text.strip()
                st.success(f"ç¿»è¯‘æˆåŠŸï¼ç¿»è¯‘åçš„ Prompt: {translated_text}")
            else:
                st.warning("âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
                # Fallback to original text if translation response is empty
        else:
            st.info("è¾“å…¥è¯­è¨€ä¸ºè‹±æ–‡ï¼Œæ— éœ€ç¿»è¯‘ã€‚")

    except LangDetectException:
        st.warning("âš ï¸ è¯­è¨€æ£€æµ‹å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
        original_language = None # Indicate detection failure
    except Exception as translation_err:
        st.error(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {translation_err}")
        st.warning("âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ Prompt è¿›è¡Œå›¾ç‰‡ç”Ÿæˆã€‚")
        original_language = None # Indicate translation error
    
    return translated_text, original_language


# --- New Function for Image-to-Image Generation ---
def generate_image_from_image_and_prompt(uploaded_image_file, prompt_text: str, api_key: str):
    """
    Generates/edits an image based on an uploaded image and a text prompt using Google Gemini.
    Displays the new image, saves it, and logs the prompt and any text response.
    """
    logging.info(f"Attempting image-to-image generation with prompt: {prompt_text}")
    try:
        pil_image = Image.open(uploaded_image_file)
        
        # Optionally display the uploaded image for confirmation
        # st.image(pil_image, caption="æ‚¨ä¸Šä¼ çš„å›¾ç‰‡ (ç”¨äºç¼–è¾‘)", use_container_width=False, width=300)

        with st.spinner(f"ğŸ¨ æ­£åœ¨æ ¹æ®æ‚¨çš„å›¾ç‰‡å’Œæè¿°ç”Ÿæˆæ–°å›¾ç‰‡..."):
            # Using the genai_client (google.genai) as per the example structure for Gemini multimodal
            client = genai_client.Client(api_key=api_key)
            
            response = client.models.generate_content(
                model="gemini-2.0-flash-preview-image-generation", # Specific model for image-to-image
                contents=[prompt_text, pil_image], # Order: text prompt, then image
                config=genai_client_types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE'] # Expecting both text and image in response
                )
            )

        if response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
            st.success("ğŸ‰ å›¾ç‰‡ç¼–è¾‘/ç”ŸæˆæˆåŠŸï¼")
            generated_image_data = None
            generated_text = None

            for part in response.candidates[0].content.parts:
                if part.text is not None:
                    generated_text = part.text
                    st.info(f"æ¨¡å‹å›å¤: {generated_text}")
                    logging.info(f"Image-to-image model text response: {generated_text}")
                elif part.inline_data is not None and part.inline_data.data:
                    generated_image_data = part.inline_data.data

            if generated_image_data:
                new_image = Image.open(BytesIO(generated_image_data))
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                # Differentiate filename for image-to-image results
                image_filename = f"{IMAGE_OUTPUT_DIR}/img2img_{timestamp}.png"
                new_image.save(image_filename)
                logging.info(f"Saved image-to-image result: {image_filename}")
                st.image(new_image, caption=f"ç”Ÿæˆ/ç¼–è¾‘åçš„å›¾ç‰‡ (å·²ä¿å­˜è‡³ {image_filename})", use_container_width=True)
            else:
                st.warning("âš ï¸ æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­æå–ç”Ÿæˆçš„å›¾ç‰‡ã€‚")
                logging.warning("Failed to extract generated image from image-to-image response.")
            
            if not generated_image_data and not generated_text:
                 st.warning("âš ï¸ æ¨¡å‹æœªè¿”å›å›¾ç‰‡æˆ–æ–‡æœ¬ã€‚è¯·æ£€æŸ¥æ‚¨çš„æç¤ºè¯æˆ–ä¸Šä¼ çš„å›¾ç‰‡ã€‚")
                 logging.warning("Image-to-image model returned no image or text.")

        else:
            st.warning("âš ï¸ å›¾ç‰‡ç¼–è¾‘/ç”Ÿæˆå¤±è´¥ã€‚å¯èƒ½æ˜¯æç¤ºè¯ä¸å½“ã€æ¨¡å‹é…ç½®é—®é¢˜ã€API æƒé™ä¸è¶³ï¼Œæˆ–å“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸã€‚")
            st.warning(f"ä½¿ç”¨çš„ Prompt: {prompt_text}")
            if response:
                st.warning(f"åŸå§‹å“åº”è¯¦æƒ…: {response}") # Log or show more details if needed
            logging.warning(f"Image-to-image generation failed. Prompt used: {prompt_text}. Response: {response}")

    except Exception as e:
        st.error(f"å›¾ç‰‡ç¼–è¾‘/ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        st.error(f"ä½¿ç”¨çš„ Prompt: {prompt_text}")
        logging.error(f"Error during image-to-image generation with prompt '{prompt_text}': {e}", exc_info=True)


# --- Logging Setup ---
LOG_FILE = "image_generation.log"
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE),
        # logging.StreamHandler() # Optionally, to also print to console
    ]
)

# --- Image Saving Configuration ---
IMAGE_OUTPUT_DIR = "generated_images"
os.makedirs(IMAGE_OUTPUT_DIR, exist_ok=True)


def generate_images_from_prompt(prompt_text: str, num_images: int, api_key: str):
    """
    Generates images based on the provided prompt using Google Imagen.
    Displays images, saves them to a folder, and logs the prompt.
    """
    logging.info(f"Attempting to generate images with prompt: {prompt_text}")
    try:
        with st.spinner(f"ğŸ§  æ­£åœ¨ç”Ÿæˆ {num_images} å¼ å›¾ç‰‡ä¸­ï¼Œè¯·ç¨å€™..."):
            client = genai_client.Client(api_key=api_key)
            response = client.models.generate_images(
                model='imagen-3.0-generate-002',
                config=genai_client_types.GenerateImagesConfig(
                    number_of_images=num_images,
                ),
                prompt=prompt_text # Pass the (potentially translated) prompt here
            )

        if response and hasattr(response, 'generated_images') and response.generated_images:
            st.success(f"ğŸ‰ æˆåŠŸç”Ÿæˆ {len(response.generated_images)} å¼ å›¾ç‰‡ï¼")
            cols = st.columns(min(num_images, 2)) # Adjust columns based on number of images, max 2
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            for i, generated_image in enumerate(response.generated_images):
                try:
                    image_bytes = generated_image.image.image_bytes
                    image = Image.open(BytesIO(image_bytes))
                    
                    # Save the image
                    image_filename = f"{IMAGE_OUTPUT_DIR}/img_{timestamp}_{i+1}.png"
                    image.save(image_filename)
                    logging.info(f"Saved image: {image_filename}")

                    with cols[i % min(num_images, 2)]: # Ensure correct column assignment
                        st.image(image, caption=f"å›¾ç‰‡ {i+1} (å·²ä¿å­˜è‡³ {image_filename})", use_container_width=True)
                except Exception as img_err:
                    st.error(f"å¤„ç†æˆ–ä¿å­˜å›¾ç‰‡ {i+1} æ—¶å‡ºé”™: {img_err}")
                    logging.error(f"Error processing/saving image {i+1}: {img_err}")
        else:
            st.warning("âš ï¸ æœªèƒ½ç”Ÿæˆå›¾ç‰‡ã€‚å¯èƒ½æ˜¯æç¤ºè¯ä¸å½“ã€æ¨¡å‹é…ç½®é—®é¢˜ã€API æƒé™ä¸è¶³ï¼Œæˆ–å“åº”ç»“æ„ä¸ç¬¦åˆé¢„æœŸã€‚")
            st.warning(f"ä½¿ç”¨çš„ Prompt: {prompt_text}") # Show the prompt used
            logging.warning(f"Failed to generate images. Prompt used: {prompt_text}")

    except Exception as e:
        st.error(f"å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        st.error(f"ä½¿ç”¨çš„ Prompt: {prompt_text}") # Show the prompt used in case of error
        logging.error(f"Error during image generation with prompt '{prompt_text}': {e}")

# --- Streamlit App UI ---
st.set_page_config(page_title="AI å›¾ç‰‡ç”Ÿæˆä¸ç¼–è¾‘", layout="wide")

st.title("ğŸ¨ AI å›¾ç‰‡ç”Ÿæˆä¸ç¼–è¾‘æœåŠ¡")
st.caption("æ”¯æŒæ–‡å­—ç”Ÿæˆå›¾ç‰‡ (Imagen 3) ä¸å›¾ç‰‡ç¼–è¾‘ (Gemini)")

# API Key Input
st.sidebar.header("âš™ï¸ é…ç½®")
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    api_key = st.sidebar.text_input("Google AI API Key:", type="password", help="åœ¨æ­¤è¾“å…¥æ‚¨çš„ Google AI API Key")

if not api_key:
    st.info("è¯·è¾“å…¥æ‚¨çš„ Google AI API Key ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
    st.sidebar.warning("API Key æœªæä¾›ã€‚")

# Mode Selection
generation_mode = st.sidebar.radio(
    "é€‰æ‹©æ¨¡å¼:",
    ("æ–‡ç”Ÿå›¾ (Text-to-Image)", "å›¾ç”Ÿå›¾ (Image-to-Image)"),
    key="generation_mode_selector"
)

# User Input Area
st.header("ğŸ–¼ï¸ ç”Ÿæˆå‚æ•°")

uploaded_image_file = None
if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
    uploaded_image_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œç¼–è¾‘:", type=["png", "jpg", "jpeg", "webp"], key="image_uploader")
    if uploaded_image_file:
        st.image(uploaded_image_file, caption="æ‚¨ä¸Šä¼ çš„å›¾ç‰‡", width=300) # Preview uploaded image

prompt_label = "å›¾ç‰‡æè¿° (Text-to-Image Prompt):"
default_prompt = "ä¸€ä¸ªå®‡èˆªå‘˜åœ¨æœˆçƒä¸Šéª‘ç€å½©è™¹è‰²çš„ç‹¬è§’å…½ï¼ŒèƒŒæ™¯æ˜¯æ˜Ÿç©ºã€‚"
if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
    prompt_label = "ç¼–è¾‘æŒ‡ä»¤ (Image-to-Image Prompt):"
    default_prompt = "ä¸ºå›¾ç‰‡ä¸­çš„ä¸»è¦å¯¹è±¡æˆ´ä¸Šä¸€é¡¶æ´¾å¯¹å¸½ã€‚"

prompt = st.text_area(prompt_label, default_prompt, height=150, key="main_prompt")


# Image count configuration - only for text-to-image
num_images_to_generate = 1 # Default
if generation_mode == "æ–‡ç”Ÿå›¾ (Text-to-Image)":
    num_images_to_generate = st.sidebar.number_input("ç”Ÿæˆå›¾ç‰‡æ•°é‡:", min_value=1, max_value=10, value=2, step=1, key="num_images_input")


# Generate Button
generate_button_label = "âœ¨ ç”Ÿæˆå›¾ç‰‡"
if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
    generate_button_label = "ğŸ¨ ç¼–è¾‘å›¾ç‰‡"
    
generate_button = st.sidebar.button(generate_button_label, use_container_width=True, disabled=not api_key)

st.markdown("---") # Main area separator

# Main logic when generate button is clicked
if generate_button:
    if not api_key:
        st.error("âŒ è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ Google AI API Keyã€‚")
    elif not prompt:
        st.error(f"âŒ è¯·è¾“å…¥{prompt_label.split('(')[0].strip()}ã€‚")
    else:
        # 1. Translate prompt if necessary (common for both modes)
        # For image-to-image, the prompt is an instruction, translation is still beneficial.
        translated_prompt, original_lang = translate_text_to_english(prompt, api_key)
        final_prompt_to_use = translated_prompt if translated_prompt else prompt
        
        log_message_intro = f"Original prompt ({original_lang})" if original_lang and original_lang != "en" and translated_prompt != prompt else "Prompt"
        if original_lang and original_lang != "en" and translated_prompt != prompt:
            logging.info(f"{log_message_intro}: {prompt}")
            logging.info(f"Translated prompt (en): {translated_prompt}")
        elif not original_lang: # Language detection failed
             logging.info(f"Prompt (language detection failed, using as is): {prompt}")
        else: # Already English or translation not needed/failed but using original
            logging.info(f"Prompt (en or using original): {prompt}")

        # 2. Generate based on mode
        if final_prompt_to_use:
            if generation_mode == "æ–‡ç”Ÿå›¾ (Text-to-Image)":
                generate_images_from_prompt(final_prompt_to_use, num_images_to_generate, api_key)
            elif generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
                if uploaded_image_file is None:
                    st.error("âŒ è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ä»¥è¿›è¡Œå›¾ç”Ÿå›¾ç¼–è¾‘ã€‚")
                else:
                    generate_image_from_image_and_prompt(uploaded_image_file, final_prompt_to_use, api_key)
        else:
            st.error("âŒ æ— æ³•è·å–ç”¨äºæ“ä½œçš„æœ‰æ•ˆ Promptã€‚")
            logging.error("Could not obtain a valid prompt for image generation/editing.")
            

# Usage Instructions and Footer
st.sidebar.markdown("---")
st.sidebar.markdown("""
**ä½¿ç”¨è¯´æ˜:**
1.  **é€šç”¨**: æ¨¡å‹ä¸»è¦æ”¯æŒè‹±æ–‡æç¤ºè¯ã€‚è‹¥ä½¿ç”¨å…¶ä»–è¯­è¨€ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•ç¿»è¯‘æˆè‹±æ–‡ã€‚API Key åœ¨å·¦ä¾§é…ç½®ã€‚
2.  **æ–‡ç”Ÿå›¾ (Text-to-Image)**: åœ¨ä¸Šæ–¹é€‰æ‹©æ­¤æ¨¡å¼ï¼Œè¾“å…¥æè¿°æ–‡å­—ï¼Œé€‰æ‹©ç”Ÿæˆæ•°é‡ï¼Œç‚¹å‡»â€œç”Ÿæˆå›¾ç‰‡â€ã€‚
3.  **å›¾ç”Ÿå›¾ (Image-to-Image)**: åœ¨ä¸Šæ–¹é€‰æ‹©æ­¤æ¨¡å¼ï¼Œä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œè¾“å…¥ç¼–è¾‘æŒ‡ä»¤ (ä¾‹å¦‚ï¼š"ç»™å›¾ç‰‡ä¸­çš„çŒ«åŠ ä¸Šä¸€é¡¶å®‡èˆªå‘˜å¤´ç›”")ï¼Œç‚¹å‡»â€œç¼–è¾‘å›¾ç‰‡â€ã€‚
""")

st.markdown("---")
st.markdown("<p style='text-align: center;'>ç”± AI åŠ©æ‰‹åŸºäºæ‚¨çš„ä»£ç æ„å»ºä¸å¢å¼º</p>", unsafe_allow_html=True)
